"""
IMDBæƒ…æ„Ÿåˆ†æå¿«é€Ÿé–‹å§‹ç¯„ä¾‹

æœ¬è…³æœ¬æ¼”ç¤ºå¦‚ä½•å¿«é€Ÿä½¿ç”¨IMDBæƒ…æ„Ÿåˆ†æå°ˆæ¡ˆï¼š
1. è¼‰å…¥è³‡æ–™å’Œé è™•ç†
2. è¨“ç·´åŸºç·šæ¨¡å‹
3. è©•ä¼°æ¨¡å‹æ€§èƒ½
4. é€²è¡Œé æ¸¬

ä½¿ç”¨æ–¹å¼:
    python examples/quick_start.py
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import time
from sklearn.model_selection import train_test_split

# å°å…¥å°ˆæ¡ˆæ¨¡çµ„
from src.data import IMDBDataLoader, TextPreprocessor
from src.models import BaselineModelManager
from src.evaluation import ModelEvaluator
from src.utils.logger import logger

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¬ IMDBæƒ…æ„Ÿåˆ†æå¿«é€Ÿé–‹å§‹")
    print("=" * 50)
    
    # 1. è¼‰å…¥è³‡æ–™
    print("\nğŸ“Š æ­¥é©Ÿ1: è¼‰å…¥IMDBè³‡æ–™é›†...")
    start_time = time.time()
    
    data_loader = IMDBDataLoader(cache_dir="data/raw")
    
    try:
        train_texts, train_labels, test_texts, test_labels = data_loader.load_data()
        print(f"âœ… è³‡æ–™è¼‰å…¥æˆåŠŸ ({time.time() - start_time:.2f}ç§’)")
        print(f"   è¨“ç·´é›†: {len(train_texts):,} ç­†")
        print(f"   æ¸¬è©¦é›†: {len(test_texts):,} ç­†")
        
        # ç²å–è³‡æ–™çµ±è¨ˆ
        stats = data_loader.get_data_statistics()
        print(f"   æ­£é¢è©•è«–æ¯”ä¾‹: {stats['train_positive_ratio']:.1%}")
        print(f"   å¹³å‡æ–‡æœ¬é•·åº¦: {stats['avg_train_length']:.1f} è©")
        
    except Exception as e:
        logger.error(f"è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
        return
    
    # ä½¿ç”¨è¼ƒå°çš„è³‡æ–™å­é›†é€²è¡Œå¿«é€Ÿæ¼”ç¤º
    if len(train_texts) > 5000:
        print("\nğŸ“ ä½¿ç”¨è³‡æ–™å­é›†é€²è¡Œå¿«é€Ÿæ¼”ç¤º...")
        train_texts = train_texts[:5000]
        train_labels = train_labels[:5000]
        test_texts = test_texts[:1000]
        test_labels = test_labels[:1000]
    
    # 2. è³‡æ–™é è™•ç†
    print("\nğŸ”§ æ­¥é©Ÿ2: æ–‡æœ¬é è™•ç†...")
    start_time = time.time()
    
    preprocessor = TextPreprocessor(
        remove_html=True,
        remove_urls=True,
        lowercase=True,
        handle_negations=True,
        remove_punctuation=False
    )
    
    # å‰µå»ºé©—è­‰é›†
    train_texts_final, val_texts, train_labels_final, val_labels = train_test_split(
        train_texts, train_labels, test_size=0.2, stratify=train_labels, random_state=42
    )
    
    # é è™•ç†æ–‡æœ¬
    train_texts_clean = preprocessor.preprocess_batch(train_texts_final)
    val_texts_clean = preprocessor.preprocess_batch(val_texts)
    test_texts_clean = preprocessor.preprocess_batch(test_texts)
    
    print(f"âœ… é è™•ç†å®Œæˆ ({time.time() - start_time:.2f}ç§’)")
    print(f"   æœ€çµ‚è¨“ç·´é›†: {len(train_texts_clean):,} ç­†")
    print(f"   é©—è­‰é›†: {len(val_texts_clean):,} ç­†")
    print(f"   æ¸¬è©¦é›†: {len(test_texts_clean):,} ç­†")
    
    # 3. è¨“ç·´æ¨¡å‹
    print("\nğŸš€ æ­¥é©Ÿ3: è¨“ç·´åŸºç·šæ¨¡å‹...")
    start_time = time.time()
    
    model_manager = BaselineModelManager(models_dir="experiments/models")
    
    # åªè¨“ç·´å¿«é€Ÿçš„æ¨¡å‹é€²è¡Œæ¼”ç¤º
    quick_models = ['logistic_regression', 'naive_bayes']
    results = {}
    
    for model_name in quick_models:
        try:
            print(f"   è¨“ç·´ {model_name}...")
            result = model_manager.train_model(
                model_name, 
                train_texts_clean, 
                train_labels_final,
                use_grid_search=False  # è·³éç¶²æ ¼æœç´¢ä»¥ç¯€çœæ™‚é–“
            )
            results[model_name] = result
            print(f"   âœ… {model_name} CVåˆ†æ•¸: {result['cv_score']:.4f}")
            
        except Exception as e:
            print(f"   âŒ {model_name} è¨“ç·´å¤±æ•—: {e}")
    
    print(f"âœ… æ¨¡å‹è¨“ç·´å®Œæˆ ({time.time() - start_time:.2f}ç§’)")
    
    # 4. æ¨¡å‹è©•ä¼°
    print("\nğŸ“ˆ æ­¥é©Ÿ4: æ¨¡å‹è©•ä¼°...")
    start_time = time.time()
    
    evaluator = ModelEvaluator()
    best_model_name = None
    best_accuracy = 0
    
    for model_name in results.keys():
        try:
            # åœ¨é©—è­‰é›†ä¸Šè©•ä¼°
            val_result = model_manager.evaluate_model(model_name, val_texts_clean, val_labels)
            
            # ä½¿ç”¨è©•ä¼°å™¨é€²è¡Œè©³ç´°åˆ†æ
            eval_result = evaluator.evaluate_classification(
                val_labels,
                val_result['predictions'],
                val_result.get('probabilities'),
                model_name
            )
            
            accuracy = eval_result['accuracy']
            print(f"   {model_name}:")
            print(f"     æº–ç¢ºç‡: {accuracy:.4f}")
            print(f"     F1åˆ†æ•¸: {eval_result['f1_score']:.4f}")
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_model_name = model_name
                
        except Exception as e:
            print(f"   âŒ {model_name} è©•ä¼°å¤±æ•—: {e}")
    
    print(f"âœ… æ¨¡å‹è©•ä¼°å®Œæˆ ({time.time() - start_time:.2f}ç§’)")
    print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (æº–ç¢ºç‡: {best_accuracy:.4f})")
    
    # 5. æœ€ä½³æ¨¡å‹æ¸¬è©¦
    if best_model_name:
        print(f"\nğŸ¯ æ­¥é©Ÿ5: ä½¿ç”¨{best_model_name}é€²è¡Œæ¸¬è©¦...")
        start_time = time.time()
        
        try:
            test_result = model_manager.evaluate_model(best_model_name, test_texts_clean, test_labels)
            test_accuracy = test_result['accuracy']
            
            print(f"âœ… æ¸¬è©¦å®Œæˆ ({time.time() - start_time:.2f}ç§’)")
            print(f"   æ¸¬è©¦é›†æº–ç¢ºç‡: {test_accuracy:.4f}")
            
            # ç”Ÿæˆåˆ†é¡å ±å‘Š
            eval_result = evaluator.evaluate_classification(
                test_labels,
                test_result['predictions'],
                test_result.get('probabilities'),
                f"{best_model_name}_test"
            )
            
            # é¡¯ç¤ºæ··æ·†çŸ©é™£ä¿¡æ¯
            cm = eval_result['confusion_matrix']
            print(f"   æ··æ·†çŸ©é™£:")
            print(f"     çœŸè² ä¾‹: {cm[0][0]}, å‡æ­£ä¾‹: {cm[0][1]}")
            print(f"     å‡è² ä¾‹: {cm[1][0]}, çœŸæ­£ä¾‹: {cm[1][1]}")
            
        except Exception as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
    
    # 6. äº’å‹•å¼é æ¸¬æ¼”ç¤º
    print("\nğŸ® æ­¥é©Ÿ6: äº’å‹•å¼é æ¸¬æ¼”ç¤º")
    
    if best_model_name:
        sample_texts = [
            "This movie was absolutely fantastic! Great acting and amazing plot.",
            "Terrible movie, waste of time. Poor acting and boring story.",
            "The film was okay, nothing special but not bad either.",
            "One of the best movies I've ever seen! Highly recommended!",
            "Worst movie ever. Don't waste your money on this garbage."
        ]
        
        print("   é æ¸¬ç¤ºä¾‹:")
        for i, text in enumerate(sample_texts, 1):
            try:
                predictions, probabilities = model_manager.predict(best_model_name, [text])
                sentiment = "æ­£é¢ğŸ˜Š" if predictions[0] == 1 else "è² é¢ğŸ˜"
                confidence = probabilities[0][predictions[0]] if probabilities is not None else 0.5
                
                print(f"   {i}. æ–‡æœ¬: {text[:50]}...")
                print(f"      é æ¸¬: {sentiment} (ä¿¡å¿ƒåº¦: {confidence:.3f})")
                
            except Exception as e:
                print(f"   âŒ é æ¸¬å¤±æ•—: {e}")
    
    # 7. ç¸½çµ
    print("\n" + "=" * 50)
    print("ğŸ‰ å¿«é€Ÿé–‹å§‹æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ“‹ ç¸½çµ:")
    
    if results:
        print("âœ… æˆåŠŸè¨“ç·´çš„æ¨¡å‹:")
        for model_name, result in results.items():
            print(f"   - {model_name}: CVåˆ†æ•¸ {result['cv_score']:.4f}")
    
    if best_model_name:
        print(f"ğŸ† æ¨è–¦æ¨¡å‹: {best_model_name}")
        print(f"ğŸ“Š æ¸¬è©¦æº–ç¢ºç‡: {test_accuracy:.4f}")
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥:")
    print("1. åŸ·è¡Œå®Œæ•´çš„Jupyter notebooksé€²è¡Œæ·±å…¥åˆ†æ")
    print("2. è¨“ç·´Transformeræ¨¡å‹ç²å¾—æ›´é«˜æº–ç¢ºç‡")
    print("3. å•Ÿå‹•APIæœå‹™: python app.py")
    print("4. ç€è¦½Webä»‹é¢: http://localhost:8000")
    
    print("\nğŸ“š æ›´å¤šä¿¡æ¯è«‹åƒè€ƒ:")
    print("- README.md: å°ˆæ¡ˆæ¦‚è¿°å’Œå¿«é€Ÿé–‹å§‹")
    print("- USAGE.md: è©³ç´°ä½¿ç”¨æŒ‡å—")
    print("- notebooks/: Jupyterå¯¦é©—ç­†è¨˜æœ¬")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâŒ ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\n\nâŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        logger.error(f"å¿«é€Ÿé–‹å§‹è…³æœ¬åŸ·è¡Œå¤±æ•—: {e}")
    finally:
        print("\nğŸ‘‹ æ„Ÿè¬ä½¿ç”¨IMDBæƒ…æ„Ÿåˆ†æå°ˆæ¡ˆï¼")