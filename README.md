# ğŸ¬ IMDBé›»å½±è©•è«–æƒ…æ„Ÿåˆ†æå°ˆæ¡ˆ

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org)
[![Transformers](https://img.shields.io/badge/Transformers-4.35+-green.svg)](https://huggingface.co/transformers/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-teal.svg)](https://fastapi.tiangolo.com/)

## ğŸ“– å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆç‚ºçµ±è¨ˆç¢©å£«æ·±åº¦å­¸ç¿’å¯¦æˆ°å°ˆæ¡ˆï¼Œä½¿ç”¨IMDB Movie Reviewsè³‡æ–™é›†é€²è¡Œæƒ…æ„Ÿåˆ†æã€‚å°ˆæ¡ˆæ¶µè“‹å¾å‚³çµ±æ©Ÿå™¨å­¸ç¿’åˆ°ç¾ä»£Transformeræ¨¡å‹çš„å®Œæ•´æŠ€è¡“æ£§ï¼Œæä¾›ç«¯åˆ°ç«¯çš„NLPè§£æ±ºæ–¹æ¡ˆã€‚

### ğŸ¯ ä¸»è¦ç›®æ¨™
- å»ºæ§‹é«˜æ•ˆèƒ½çš„é›»å½±è©•è«–æƒ…æ„Ÿåˆ†æç³»çµ±ï¼ˆæº–ç¢ºç‡ â‰¥ 90%ï¼‰
- æ¯”è¼ƒå‚³çµ±MLã€æ·±åº¦å­¸ç¿’ã€Transformeræ¨¡å‹çš„æ€§èƒ½å·®ç•°
- æä¾›ç”Ÿç”¢ç´šçš„APIæœå‹™å’ŒWebä»‹é¢
- å»ºç«‹å®Œæ•´çš„MLOpså·¥ä½œæµç¨‹

## ğŸ—ï¸ å°ˆæ¡ˆæ¶æ§‹

```
imdb_sentiment_analysis/
â”œâ”€â”€ ğŸ“ data/                    # è³‡æ–™ç›®éŒ„
â”‚   â”œâ”€â”€ raw/                   # åŸå§‹IMDBè³‡æ–™é›†
â”‚   â”œâ”€â”€ processed/             # é è™•ç†å¾Œè³‡æ–™
â”‚   â””â”€â”€ external/              # å¤–éƒ¨è³‡æ–™
â”œâ”€â”€ ğŸ“ src/                     # æ ¸å¿ƒç¨‹å¼ç¢¼
â”‚   â”œâ”€â”€ data/                  # è³‡æ–™è™•ç†æ¨¡çµ„
â”‚   â”œâ”€â”€ models/                # æ¨¡å‹å®šç¾©
â”‚   â”‚   â”œâ”€â”€ baseline.py        # å‚³çµ±MLæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ deep_learning.py   # æ·±åº¦å­¸ç¿’æ¨¡å‹
â”‚   â”‚   â””â”€â”€ transformers.py    # Transformeræ¨¡å‹
â”‚   â”œâ”€â”€ training/              # è¨“ç·´æ¡†æ¶
â”‚   â”œâ”€â”€ evaluation/            # è©•ä¼°æ¨¡çµ„
â”‚   â”œâ”€â”€ inference/             # æ¨ç†æœå‹™
â”‚   â””â”€â”€ utils/                 # å·¥å…·å‡½æ•¸
â”œâ”€â”€ ğŸ“ notebooks/               # Jupyterå¯¦é©—ç­†è¨˜æœ¬
â”œâ”€â”€ ğŸ“ experiments/             # å¯¦é©—çµæœå’Œæ¨¡å‹
â””â”€â”€ ğŸ“„ app.py                   # APIæœå‹™å…¥å£
```

## ğŸ› ï¸ æŠ€è¡“æ£§

### æ ¸å¿ƒæ¡†æ¶
- **PyTorch 2.0+**: æ·±åº¦å­¸ç¿’æ¡†æ¶
- **Transformers**: Hugging Faceé è¨“ç·´æ¨¡å‹
- **FastAPI**: é«˜æ€§èƒ½APIæ¡†æ¶
- **scikit-learn**: å‚³çµ±æ©Ÿå™¨å­¸ç¿’

### æ¨¡å‹æ¶æ§‹
| é¡å‹ | æ¨¡å‹ | ç›®æ¨™æº–ç¢ºç‡ | ç‰¹é» |
|------|------|-----------|------|
| å‚³çµ±ML | é‚è¼¯å›æ­¸ + TF-IDF | 80%+ | å¿«é€ŸåŸºç·š |
| å‚³çµ±ML | SVM + TF-IDF | 82%+ | ç©©å®šæ€§èƒ½ |
| æ·±åº¦å­¸ç¿’ | TextCNN | 85%+ | å·ç©ç‰¹å¾µæå– |
| æ·±åº¦å­¸ç¿’ | BiLSTM | 87%+ | åºåˆ—å»ºæ¨¡ |
| Transformer | DistilBERT | 91%+ | è¼•é‡åŒ–BERT |
| Transformer | RoBERTa | 93%+ | å¼·åŒ–ç‰ˆBERT |

> **æ³¨æ„**: ä¸Šè¿°æ•¸å€¼ç‚ºé æœŸç›®æ¨™ï¼Œå¯¦éš›æ€§èƒ½éœ€è¦é€šéè¨“ç·´å’Œæ¸¬è©¦ç²å¾—ã€‚

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. ç’°å¢ƒè¨­ç½®

```bash
# å…‹éš†å°ˆæ¡ˆ
git clone <repository-url>
cd imdb_sentiment_analysis

# å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# æˆ–
.venv\Scripts\activate     # Windows

# å®‰è£ä¾è³´
pip install -r requirements.txt

# ä¸‹è¼‰spaCyæ¨¡å‹
python -m spacy download en_core_web_sm
```

### 2. è³‡æ–™æ¢ç´¢å’Œæ¨¡å‹è¨“ç·´

```bash
# å•Ÿå‹•Jupyter Lab
jupyter lab

# ä¾åºåŸ·è¡Œç­†è¨˜æœ¬
notebooks/01_data_exploration.ipynb      # è³‡æ–™æ¢ç´¢åˆ†æ
notebooks/02_baseline_models.ipynb       # å‚³çµ±MLåŸºç·š
notebooks/03_deep_learning_models.ipynb  # æ·±åº¦å­¸ç¿’æ¨¡å‹
notebooks/04_transformer_models.ipynb    # Transformeræ¨¡å‹
notebooks/05_api_demo.ipynb             # APIæœå‹™æ¸¬è©¦
```

### 3. å•Ÿå‹•APIæœå‹™

```bash
# å•Ÿå‹•FastAPIæœå‹™
python app.py

# æœå‹™å°‡é‹è¡Œåœ¨ http://localhost:8000
# ğŸ“š APIæ–‡æª”: http://localhost:8000/docs
# ğŸŒ Webä»‹é¢: http://localhost:8000/
# ğŸ” å¥åº·æª¢æŸ¥: http://localhost:8000/health
```

## ğŸ“Š APIä½¿ç”¨ç¯„ä¾‹

### å–®å€‹é æ¸¬
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "This movie was absolutely fantastic!"}'
```

### æ‰¹æ¬¡é æ¸¬
```bash
curl -X POST "http://localhost:8000/predict/batch" \
     -H "Content-Type: application/json" \
     -d '{"texts": ["Great movie!", "Terrible film", "It was okay"]}'
```

### Pythonå®¢æˆ¶ç«¯
```python
import requests

# å–®å€‹é æ¸¬
response = requests.post(
    "http://localhost:8000/predict",
    json={"text": "Amazing cinematography and stellar performances!"}
)
result = response.json()
print(f"æƒ…æ„Ÿ: {result['sentiment']}, ä¿¡å¿ƒåº¦: {result['confidence']:.3f}")

# æ‰¹æ¬¡é æ¸¬
response = requests.post(
    "http://localhost:8000/predict/batch",
    json={"texts": ["Love this movie!", "Worst film ever", "Not bad"]}
)
results = response.json()
for r in results['results']:
    print(f"{r['text']} -> {r['sentiment']} ({r['confidence']:.3f})")
```

## ğŸ”§ é€²éšä½¿ç”¨

### è‡ªå®šç¾©æ¨¡å‹é æ¸¬
```python
from src.inference import SentimentPredictor

# è¼‰å…¥ç‰¹å®šæ¨¡å‹
predictor = SentimentPredictor(
    model_path="experiments/models/distilbert_imdb",
    model_type="transformer"
)

# é æ¸¬
result = predictor.predict_single("This film is a masterpiece!")
print(result)
```

### è¨“ç·´è‡ªå·±çš„æ¨¡å‹
```python
from src.models import DistilBERTClassifier, TransformerTrainer
from src.data import IMDBDataLoader, IMDBDataset

# è¼‰å…¥è³‡æ–™
data_loader = IMDBDataLoader()
train_texts, train_labels, _, _ = data_loader.load_data()

# å‰µå»ºæ¨¡å‹
model = DistilBERTClassifier(num_labels=2)

# è¨“ç·´
trainer = TransformerTrainer(model, train_loader, val_loader)
trainer.setup_optimizer_and_scheduler()
history = trainer.train(epochs=3)
```

## ğŸ“ˆ æ€§èƒ½åŸºæº–

### æ¨¡å‹æ¯”è¼ƒ (IMDBæ¸¬è©¦é›†)
```
ğŸ“Š æ¨¡å‹æ€§èƒ½ç¸½çµ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ¨¡å‹               æº–ç¢ºç‡    F1-Score   æ¨ç†æ™‚é–“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
é‚è¼¯å›æ­¸ + TF-IDF   80.2%     0.798      <1ms
SVM + TF-IDF       82.1%     0.815      2ms
æ¨¸ç´ è²è‘‰æ–¯          75.8%     0.751      <1ms
TextCNN            85.3%     0.849      5ms
BiLSTM             87.1%     0.867      10ms
DistilBERT         91.2%     0.910      20ms
RoBERTa            93.1%     0.925      50ms
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### APIæ€§èƒ½
- **ååé‡**: ~50 requests/sec (DistilBERT)
- **éŸ¿æ‡‰æ™‚é–“**: å¹³å‡ 20-100ms
- **ä¸¦ç™¼æ”¯æ´**: æ”¯æ´å¤šç”¨æˆ¶åŒæ™‚è¨ªå•
- **è³‡æºä½¿ç”¨**: CPU ~2GB RAM, GPU ~4GB VRAM

## ğŸ” å°ˆæ¡ˆç‰¹è‰²

### âœ¨ æ ¸å¿ƒåŠŸèƒ½
- ğŸ¯ **å¤šæ¨¡å‹æ”¯æ´**: å‚³çµ±MLåˆ°Transformerçš„å®Œæ•´æŠ€è¡“æ£§
- ğŸš€ **ç”Ÿç”¢ç´šAPI**: FastAPI + è‡ªå‹•æ–‡æª” + å¥åº·æª¢æŸ¥
- ğŸ“Š **å®Œæ•´è©•ä¼°**: æ··æ·†çŸ©é™£ã€ROCæ›²ç·šã€çµ±è¨ˆé¡¯è‘—æ€§æ¸¬è©¦
- ğŸ”„ **æ¨¡å‹ç†±åˆ‡æ›**: å‹•æ…‹è¼‰å…¥ä¸åŒæ¨¡å‹ç„¡éœ€é‡å•Ÿæœå‹™
- ğŸ“± **Webç•Œé¢**: å…§å»ºç°¡æ½”çš„æ¸¬è©¦ç•Œé¢

### ğŸ›¡ï¸ å·¥ç¨‹å¯¦è¸
- ğŸ“ **å®Œæ•´æ–‡æª”**: APIè‡ªå‹•æ–‡æª” + ä½¿ç”¨æŒ‡å—
- ğŸ§ª **å…¨é¢æ¸¬è©¦**: å–®å…ƒæ¸¬è©¦ + æ•´åˆæ¸¬è©¦ + æ€§èƒ½æ¸¬è©¦
- ğŸ“ˆ **å¯¦é©—è¿½è¹¤**: è©³ç´°çš„è¨“ç·´æ­·å²å’Œæ¨¡å‹æ¯”è¼ƒ
- ğŸ”§ **æ¨¡çµ„åŒ–è¨­è¨ˆ**: é«˜å…§èšä½è€¦åˆçš„ç¨‹å¼æ¶æ§‹
- ğŸ“¦ **å®¹æ˜“éƒ¨ç½²**: Dockeræ”¯æ´ + ä¾è³´ç®¡ç†

## ğŸ¤ è²¢ç»æŒ‡å—

æ­¡è¿æäº¤Issueå’ŒPull Requestï¼

### é–‹ç™¼ç’°å¢ƒè¨­ç½®
```bash
# å®‰è£é–‹ç™¼ä¾è³´
pip install -r requirements.txt
pip install black isort pytest

# ç¨‹å¼ç¢¼æ ¼å¼åŒ–
black src/
isort src/

# åŸ·è¡Œæ¸¬è©¦
pytest tests/
```

**ğŸ¬ é–‹å§‹æ‚¨çš„æƒ…æ„Ÿåˆ†æä¹‹æ—…ï¼**