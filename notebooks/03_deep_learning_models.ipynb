{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度學習模型實作\n",
    "\n",
    "本筆記本實作和訓練深度學習模型：\n",
    "- TextCNN: 卷積神經網路文本分類\n",
    "- BiLSTM: 雙向長短期記憶網路\n",
    "- GRU: 門控循環單元\n",
    "\n",
    "比較不同架構的性能表現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要套件\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# 自定義模組\n",
    "from src.data import IMDBDataLoader, TextPreprocessor, IMDBDataset\n",
    "from src.models.deep_learning import TextCNN, BiLSTM, GRUClassifier, DeepLearningModelManager\n",
    "from src.training.trainer import DeepLearningTrainer\n",
    "from src.evaluation.evaluator import ModelEvaluator\n",
    "from src.utils.logger import logger\n",
    "\n",
    "# 設定隨機種子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 檢查GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"使用設備: {device}\")\n",
    "print(\"套件載入完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入和預處理資料\n",
    "logger.info(\"載入IMDB資料集...\")\n",
    "\n",
    "data_loader = IMDBDataLoader(cache_dir=\"../data/raw\")\n",
    "train_texts, train_labels, test_texts, test_labels = data_loader.load_data()\n",
    "\n",
    "# 創建驗證集\n",
    "train_texts_final, val_texts, train_labels_final, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, stratify=train_labels, random_state=42\n",
    ")\n",
    "\n",
    "# 文本預處理\n",
    "preprocessor = TextPreprocessor(\n",
    "    remove_html=True,\n",
    "    remove_urls=True,\n",
    "    lowercase=True,\n",
    "    handle_negations=True\n",
    ")\n",
    "\n",
    "train_texts_clean = preprocessor.preprocess_batch(train_texts_final)\n",
    "val_texts_clean = preprocessor.preprocess_batch(val_texts)\n",
    "test_texts_clean = preprocessor.preprocess_batch(test_texts)\n",
    "\n",
    "print(f\"訓練集: {len(train_texts_clean)}\")\n",
    "print(f\"驗證集: {len(val_texts_clean)}\")\n",
    "print(f\"測試集: {len(test_texts_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立詞彙表和數值化\n",
    "def build_vocab(texts, max_vocab_size=10000):\n",
    "    \"\"\"建立詞彙表\"\"\"\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        word_counts.update(words)\n",
    "    \n",
    "    # 取最常見的詞彙\n",
    "    most_common = word_counts.most_common(max_vocab_size - 2)  # 保留<UNK>和<PAD>\n",
    "    \n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for word, _ in most_common:\n",
    "        vocab[word] = len(vocab)\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def texts_to_sequences(texts, vocab, max_length=256):\n",
    "    \"\"\"將文本轉換為數值序列\"\"\"\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        seq = [vocab.get(word, vocab['<UNK>']) for word in words]\n",
    "        \n",
    "        # 截斷或填充\n",
    "        if len(seq) > max_length:\n",
    "            seq = seq[:max_length]\n",
    "        else:\n",
    "            seq.extend([vocab['<PAD>']] * (max_length - len(seq)))\n",
    "        \n",
    "        sequences.append(seq)\n",
    "    \n",
    "    return np.array(sequences)\n",
    "\n",
    "# 建立詞彙表\n",
    "vocab = build_vocab(train_texts_clean, max_vocab_size=10000)\n",
    "vocab_size = len(vocab)\n",
    "max_length = 256\n",
    "\n",
    "print(f\"詞彙表大小: {vocab_size}\")\n",
    "print(f\"最大序列長度: {max_length}\")\n",
    "\n",
    "# 轉換為數值序列\n",
    "X_train = texts_to_sequences(train_texts_clean, vocab, max_length)\n",
    "X_val = texts_to_sequences(val_texts_clean, vocab, max_length)\n",
    "X_test = texts_to_sequences(test_texts_clean, vocab, max_length)\n",
    "\n",
    "y_train = np.array(train_labels_final)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "print(f\"訓練資料形狀: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 轉換為張量\n",
    "train_dataset = TensorDataset(torch.LongTensor(X_train), torch.LongTensor(y_train))\n",
    "val_dataset = TensorDataset(torch.LongTensor(X_val), torch.LongTensor(y_val))\n",
    "test_dataset = TensorDataset(torch.LongTensor(X_test), torch.LongTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"訓練批次數: {len(train_loader)}\")\n",
    "print(f\"驗證批次數: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練TextCNN模型\n",
    "logger.info(\"訓練TextCNN模型...\")\n",
    "\n",
    "model_manager = DeepLearningModelManager(device=device)\n",
    "\n",
    "# 創建TextCNN模型\n",
    "textcnn_model = model_manager.create_model(\n",
    "    'textcnn', \n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=128,\n",
    "    num_filters=100,\n",
    "    filter_sizes=[3, 4, 5]\n",
    ")\n",
    "\n",
    "# 創建訓練器\n",
    "textcnn_trainer = DeepLearningTrainer(\n",
    "    model=textcnn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    output_dir='../experiments/models'\n",
    ")\n",
    "\n",
    "# 設置優化器\n",
    "textcnn_trainer.setup_optimizer_and_scheduler(\n",
    "    learning_rate=1e-3,\n",
    "    optimizer_type='adam',\n",
    "    scheduler_type='step',\n",
    "    step_size=5,\n",
    "    gamma=0.5\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "textcnn_history = textcnn_trainer.train(\n",
    "    epochs=10,\n",
    "    early_stopping_patience=3,\n",
    "    model_name='textcnn_best'\n",
    ")\n",
    "\n",
    "print(\"TextCNN訓練完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練BiLSTM模型\n",
    "logger.info(\"訓練BiLSTM模型...\")\n",
    "\n",
    "# 創建BiLSTM模型\n",
    "bilstm_model = model_manager.create_model(\n",
    "    'bilstm',\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_dim=64,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "# 創建訓練器\n",
    "bilstm_trainer = DeepLearningTrainer(\n",
    "    model=bilstm_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    output_dir='../experiments/models'\n",
    ")\n",
    "\n",
    "# 設置優化器\n",
    "bilstm_trainer.setup_optimizer_and_scheduler(\n",
    "    learning_rate=1e-3,\n",
    "    optimizer_type='adam',\n",
    "    scheduler_type='step'\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "bilstm_history = bilstm_trainer.train(\n",
    "    epochs=10,\n",
    "    early_stopping_patience=3,\n",
    "    model_name='bilstm_best'\n",
    ")\n",
    "\n",
    "print(\"BiLSTM訓練完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製訓練歷史\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"繪製訓練歷史\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # 損失曲線\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_title(f'{model_name} - Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # 準確率曲線\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc')\n",
    "    axes[1].plot(history['val_acc'], label='Val Acc')\n",
    "    axes[1].set_title(f'{model_name} - Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 繪製訓練歷史\n",
    "plot_training_history(textcnn_history, 'TextCNN')\n",
    "plot_training_history(bilstm_history, 'BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型評估和比較\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# 載入最佳模型進行測試\n",
    "textcnn_trainer.load_model('../experiments/models/textcnn_best.pth')\n",
    "bilstm_trainer.load_model('../experiments/models/bilstm_best.pth')\n",
    "\n",
    "# 在測試集上預測\n",
    "textcnn_preds, textcnn_probs = textcnn_trainer.predict(test_loader)\n",
    "bilstm_preds, bilstm_probs = bilstm_trainer.predict(test_loader)\n",
    "\n",
    "# 評估結果\n",
    "textcnn_results = evaluator.evaluate_classification(\n",
    "    y_test, textcnn_preds, textcnn_probs, 'TextCNN'\n",
    ")\n",
    "\n",
    "bilstm_results = evaluator.evaluate_classification(\n",
    "    y_test, bilstm_preds, bilstm_probs, 'BiLSTM'\n",
    ")\n",
    "\n",
    "# 模型比較\n",
    "comparison_df = evaluator.compare_models(evaluator.evaluation_results)\n",
    "print(\"深度學習模型性能比較:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# 生成評估報告\n",
    "report = evaluator.generate_evaluation_report(evaluator.evaluation_results)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}